# FastText Word Embedding Custom Model

Word vectorization is a crucial step in NLP but many word embedding models take too much memory to run ðŸ“ˆðŸ“ˆ
<br/>
<br/>
This is how you can vectorize your dataset with minimum memory consumption using FastText ðŸ“‰ðŸ“‰
<br/>
<br/>
You can download [corpus.txt](https://drive.google.com/file/d/1MGznr28Lj6-nDGWIB5E8tg7Z1t0roanl/view?usp=sharing) from this repo ðŸ“¥ðŸ“¥
